<!DOCTYPE html>
<html>
<head>
<title>Survey Tool</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../static/css/layout.css">
<link rel="stylesheet" type="text/css" href="../static/css/content.css">
<link rel="stylesheet" type="text/css" href="../static/css/bootstrap.css">
<link rel="stylesheet" type="text/css" href="../static/css/bootstrap.css.map">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
<script src="https://d3js.org/d3.v7.min.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
</script>
</head>
<body>
    <div class="layout learnMaterial">
        <div class="navDiv"></div>
        <div class="prog">
          <div class="progContent" style="width: calc(8.333%*6);"></div>
        </div>
        <div class="contentDiv">
          <h1>Disparate Impact</h1>
          <p><b>Machine learning</b>(<i>ML</i>) is commonly used to make decisions in practice. For example, in a loan case, banks often decide to approve or deny a borrower with the assistance of <i>ML</i> models, with the borrower's information as the input of the <i>ML</i> model, such as age, gender, employment, etc. However, it turned out that the ML model can be biased in a way that the model is more likely to approve the loan of male borrowers than female borrowers, even though they have a similar background. 
            In this section, we aim to learn a popular fairness metric, called <b>Disparate Impact</b>, to mathematically measure the fairness of an <i>ML</i> model.</p>
          <p>
            Before that, we need to learn the <b>confusion matrix</b> first. The confusion matrix enables the comparison between the predictions of the <i>ML</i> model and the actual outcome (ground truth) on a data set. Confusion matrices are in the form of a $2*2$ matrix, as shown below. The rows represent the ground truth — i.e., the number of people who got approved for the loan ($p$) and the number of people who were denied ($n$). Columns represent the number of people the model predicted were approved for the loan $p’$ and how many were denied $n’$. 
            Each of the $4$ cells represents the number of times predictions matched or mismatched with the ground truth.
          </p>
          <img src="../static/figs/confusionMatrix.png">
          <p>
            <li><b>True positive</b> ($TP$) = model correctly predicts loan was approved</li>
            <li><b>False negative</b> ($FN$) = model says deny loan, but the loan was actually approved</li>
            <li><b>False positive</b> ($FP$) = model predicts approval the loan, but the loan was actually denied</li>
            <li><b>True negative</b> ($TN$) = model correctly predicts loan was denied</li>
          </p>
          <p>
            Based on understanding the confusion matrix, let’s learn about <b>Disparate Impact</b>. Consider the example below, where the two confusion matrices 
            represent the results of an <i>ML</i> model on the men group (<b>privileged group</b>) and the women group (<b>unprivileged group</b>), respectively.
          </p>
          <div id="visualCompo" class="visualComponentContainer FairMetricsPanel"></div>
          <div class="CMDiv"></div>

          <p><b>Disparate Impact</b> (<b>DI</b>) compares the proportion of individuals in the unprivileged group who received a favorable prediction to the proportion of individuals in the privileged group who received a favorable prediction. The calculation involves the proportion of the unprivileged group that received the positive outcome divided by the proportion of the privileged group that received the positive outcome. 
            As shown in the above visualization, the ideal value of this metric is $1.0$ or $100\%$, and the value in this example would be $(60/100)/(70/100)= 0.85$ or $85\%$. Please increase or decease the number in the confusion matrices above by clicking on the symbol to have a look at how Disparate Impact changes.
          </p>
          <p style="color: #4372C4">
            <b>Please think about the following questions</b>:
            <li>How will Disparate Impact change when reducing the number of False Negatives in either the privileged group or the unprivileged group?</li>
            <li>How will Disparate Impact change when increasing the number of True Positives in the privileged group?</li>
          </p>
          <p style="bottom: -20px; margin-bottom: 0; color: red; font-weight: 500;">Please note that once you start post-test, you will not be allowed to access the material.</p>
          <div class="d-grid gap-2 d-md-flex justify-content-md-center">
            <form action="posttestIntro" method="post">
            </form>
            <button class="btn btn-primary me-md-2 cusBtn" onclick="submitInteractNum()">Start Post-test</button>
          </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8" crossorigin="anonymous"></script>
    <script src="../static/js/global.js"></script>
    <script src="../static/js/init.js"></script>
    <script src="../static/js/confusionMtxPanel.js"></script>
    <script src="../static/js/fairMetrics.js"></script>
  </body>
</html>